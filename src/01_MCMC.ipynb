{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "consistent-adult",
   "metadata": {},
   "source": [
    "Maxime Marchand\n",
    "# Astrophysics and Data science : Project 01\n",
    "## Make your own MCMC sampler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "right-modem",
   "metadata": {},
   "source": [
    "### Part 3  : The forward model\n",
    ">##### 3.a \n",
    ">Show that the position of the star in the orbital frame at time $t$ is\n",
    ">\n",
    ">\\begin{equation}\n",
    "r(t) = - a \\frac{m}{m+M} \\begin{pmatrix} \\cos(n(t-t_0)) \\\\ \\sin(n(t-t_0)) \\\\ 0 \\end{pmatrix}\n",
    "\\quad\\quad ; \\quad\\quad n = \\sqrt{\\frac{G(m+M)}{a^3}} = \\frac{2\\pi}{P}\n",
    "\\end{equation}\n",
    ">Where $t_0$ is the time of passage at the ascending node and $n = \\sqrt{\\frac{G(m+M)}{a^3}} = \\frac{2\\pi}{P}$ is the mean motion, and $P$ is the orbital period.\n",
    "\n",
    "The image below illustrates on the left the two planes defined, and the observer position. The inclination is defined as the angle between the two planes. On the right, an illustration of the Star - Planet system, at initial time $t_0$ and $t = t_0 + \\omega t$, seen from the top, perpendicular to the orbital plane.\n",
    "\n",
    "<img src='images/01_starPlanet.png' width=700>\n",
    "\n",
    "For a generic circular motion, the position vector $r'(t)$ in the orbital frame $\\{\\mathbf{\\hat{x}}', \\mathbf{\\hat{y}}', \\mathbf{\\hat{z}}'\\}$ can be written as :\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathbf{r}'(t) = \\tilde{A} \\cos(\\omega t + \\varphi_1) \\; \\mathbf{\\hat{x}'} + \\tilde{A} \\sin(\\omega t + \\varphi_2) \\; \\mathbf{\\hat{y}'}\n",
    "\\end{equation}\n",
    "\n",
    "Where $\\omega = 2\\pi/P$ is the angular velocity, $\\tilde{A}$ the amplitude, and $\\varphi_{1, 2}$ are the phases. To determine $\\varphi_{1,2}$, one can use the initial condition imposing that the planet is located at the vernal point at $t = t_0$ : $\\mathbf{r'}(t_0) = -\\tilde{A} \\; \\mathbf{\\hat{x}'}$ :\n",
    "\n",
    "\\begin{array}{ccccccc}\n",
    "\\cos(2\\pi t_0/P + \\varphi_1) & = & -1 & \\Rightarrow & 2\\pi t_0/P + \\varphi_1 = \\pi & \\Rightarrow & \\varphi_1 = \\pi - 2\\pi t_0/P \\\\\n",
    "\\sin(2\\pi t_0/P + \\varphi_2) & = & 0 & \\Rightarrow & 2\\pi t_0/P + \\varphi_2 = \\pi & \\Rightarrow & \\varphi_2 = \\pi - 2\\pi t_0/P \\\\\n",
    "\\end{array}\n",
    "\n",
    "We thus have :\n",
    "\n",
    "\\begin{array}{ccccc}\n",
    "\\cos(2\\pi t/P + \\pi - 2\\pi t_0/P) & = & - \\cos(2\\pi(t-t_0)/P) & = & - \\cos(n(t-t_0))\\\\\n",
    "\\sin(2\\pi t/P + \\pi - 2\\pi t_0/P) & = & - \\sin(2\\pi(t-t_0)/P) & = & - \\sin(n(t-t_0))\n",
    "\\end{array}\n",
    "\n",
    "Finally, one can find the amplitude $\\tilde{A}$ using the definition of the barycenter : $\\tilde{A} = a\\frac{m}{m+M}$. Putting this all together allows us to find the desired expression :\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathbf{r}'(t) = -a \\frac{m}{M+m} \\begin{pmatrix} \\cos(n(t-t_0)) \\\\ \\sin(n(t-t_0)) \\\\ 0 \\end{pmatrix}\n",
    "\\end{equation}\n",
    "\n",
    ">##### 3.b\n",
    ">Show that the velocity of the star projected onto the $z$ axis at time $t$ is\n",
    "\\begin{equation}\n",
    "V(t) = V_0 - \\frac{(Gn)^{1/3}}{(m+M)^{2/3}}m\\sin(i)\\cos(n(t-t_0))\n",
    "\\end{equation}\n",
    "> Where $V_0$ is the velocity of the system barycenter with respect to the observer.\n",
    "\n",
    "\n",
    "In order to compute the $\\hat{z}$-component of the velocity, we want to express the position vector $\\mathbf{r}(t)$ computed above in the reference frame $\\{\\mathbf{\\hat{x}}, \\mathbf{\\hat{y}}, \\mathbf{\\hat{z}}\\}$. Such a transformation corresponds to a rotation around the basis vector $\\mathbf{\\hat{x}}$, whose matrix is given by (looking at first figure can be helpful) :\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{bmatrix} \\mathbf{\\hat{x}} \\\\ \\mathbf{\\hat{y}} \\\\ \\mathbf{\\hat{z}} \\end{bmatrix} = \n",
    "\\begin{bmatrix} 1 & 0 & 0 \\\\ 0 & \\cos(i) & -\\sin(i) \\\\ 0 & \\sin(i) & \\cos(i)  \\end{bmatrix}\n",
    "\\begin{bmatrix} \\mathbf{\\hat{x}}' \\\\ \\mathbf{\\hat{y}}' \\\\ \\mathbf{\\hat{z}}' \\end{bmatrix}\n",
    "\\end{equation}\n",
    "\n",
    "We can apply this matrix on $\\mathbf{r'}(t)$ and keep the $\\hat{z}$-component :\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathbf{r}_z(t) = - a \\frac{m}{m+M} \\sin(i) \\sin(n(t-t_0))\n",
    "\\end{equation}\n",
    "\n",
    "The velocity is given by the time-derivative :\n",
    "\n",
    "\\begin{equation}\n",
    "V(t) \\equiv \\dot{\\mathbf{r}}_z(t) = - a n \\frac{m}{m+M} \\sin(i) \\cos(n(t-t_0))\n",
    "\\end{equation}\n",
    "\n",
    "Replacing $a$ using the equation $n = \\sqrt{G(m+M)/a^3}$ allows us to find the desired expression :\n",
    "\n",
    "\\begin{equation}\n",
    "V(t) = V_0 - \\frac{(Gn)^{1/3}}{(m+M)^{2/3}}m\\sin(i)\\cos(n(t-t_0))\n",
    "\\end{equation}\n",
    "\n",
    "Where $V_0$ is added in order to take into consideration the velocity of the system Star - Planet.\n",
    "\n",
    "\n",
    ">##### 3.c\n",
    ">We assume that we have $N$ radial velocity measurements taken at times $(t_k)_{k=1..N}$. We also assume that these measurements are affected by Gaussian white (i.e., uncorrelated) noise, and that the instrument errorbar of the $k$-th measurement is $\\sigma_k$. Give the expression of the likelihood (or loglikelihood) function.\n",
    "\n",
    "As we are considering that the measurments are affected by Gaussian noise, the Likelihood function for such a distribution is given by :\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathcal{L} = \\prod_k \\frac{1}{\\sqrt{2\\pi\\sigma_k^2}} \\exp\\left[- \\frac{(y_k - V(t_k))^2}{2\\sigma_k^2} \\right]\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    ">##### 3.d\n",
    ">In the rest of this exercise, we will not use directly the model of Eq. (2), but\n",
    ">\n",
    ">\\begin{equation}\n",
    "V(t) = A cos(nt) + B sin(nt) + C\n",
    "\\end{equation}\n",
    ">\n",
    ">What is the advantage of this latter formulation? Give the relations between the parameters $A$, $B$, $C$ and the orbital/physical parameters of Eq. (2).\n",
    "\n",
    "\n",
    "Given the relation $\\cos(a-b) = \\cos(a)\\cos(b) + \\sin(a)\\sin(b)$, one can rewrite the eq. for $V(t)$ with the new model, with $A, B$ and $C$ given by :\n",
    " \n",
    "\\begin{eqnarray}\n",
    "A & = & -\\frac{(Gn)^{1/3}}{(m+M)^{2/3}} m \\sin(i) \\cos(nt_0) \\\\\n",
    "&& \\\\\n",
    "B & = & -\\frac{(Gn)^{1/3}}{(m+M)^{2/3}} m \\sin(i)\\sin(nt_0)  \\\\\n",
    "&& \\\\\n",
    "C & = & V_0\n",
    "\\end{eqnarray}\n",
    " Defining the matrix $\\mathbf{X}$ and vector $\\mathbf{a}$ as :\n",
    "\\begin{equation}\n",
    "\\mathbf{X} = \\begin{bmatrix} \\cos(nt_{1}) & \\sin(nt_{1}) & 1 \\\\ \\cos(nt_{2}) & \\sin(nt_{2}) & 1 \\\\ \\vdots & \\vdots & \\vdots \\\\ \\cos(nt_{N}) & \\sin(nt_{N}) & 1 \\end{bmatrix}\n",
    "\\quad ; \\quad\n",
    "\\mathbf{a} = \\begin{bmatrix} A \\\\ B \\\\ C \\end{bmatrix}\n",
    "\\end{equation}\n",
    "We can thus write our model as $V(t) = \\mathbf{X}\\cdot\\mathbf{a}$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recovered-uganda",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-29T19:12:56.529887Z",
     "start_time": "2023-11-29T19:12:53.939239Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from astropy.io import ascii\n",
    "from astropy import constants as const\n",
    "import corner\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "russian-prague",
   "metadata": {},
   "source": [
    "### Part 4 : Point estimates (maximum likelihood)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "changing-tattoo",
   "metadata": {},
   "source": [
    ">#### Point a)\n",
    "We assume that the mean-motion $n$ is known (thanks to a periodogram approach for instance). Give the\n",
    "expression of the maximum likelihood estimate of $\\theta = (A, B, C)$.\n",
    "\n",
    "The maximum likelihood estimate of $\\theta$ is given by :\n",
    "\n",
    "\\begin{equation}\n",
    "\\theta_{MLE} = C_\\theta X^T\\Sigma^{-1}y\n",
    "\\end{equation}\n",
    "\n",
    "Where $C_{\\theta} = \\left[ X^T\\Sigma^{-1} X \\right]^{-1}$ is the covariance matrix of $\\theta$ and $\\Sigma^{-1}$ is the weight matrix of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "excited-short",
   "metadata": {},
   "source": [
    ">#### Point b)\n",
    "Load the data in the file rv_data.txt and compute the maximum likelihood values of the parameters $\\theta$ assuming a period of 6.5 d for the planet.\n",
    "\n",
    "Before computing the best fit parameters $A$, $B$ and $C$, let have a look at the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extended-microphone",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-29T19:12:57.388490Z",
     "start_time": "2023-11-29T19:12:56.535862Z"
    }
   },
   "outputs": [],
   "source": [
    "# Reading file\n",
    "inFileName = 'rv_data.txt'\n",
    "data = dict(ascii.read(inFileName))\n",
    "\n",
    "# Replacing key names\n",
    "data['t']  = data.pop('col1')\n",
    "data['y']  = data.pop('col2')\n",
    "data['ey'] = data.pop('col3')\n",
    "\n",
    "# Plotting the data\n",
    "fig, ax = plt.subplots(figsize=(16, 3), dpi=300)\n",
    "ax.set_xlabel(\"Time\")\n",
    "ax.set_ylabel(\"Radial velocity\")\n",
    "ax.errorbar(data['t'], data['y'], yerr=data['ey'], fmt='ok');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "final-company",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-29T19:12:57.401181Z",
     "start_time": "2023-11-29T19:12:57.394021Z"
    }
   },
   "outputs": [],
   "source": [
    "def fit_model(data, P):\n",
    "    n      = 2 * np.pi / P\n",
    "    # Columns of the basis matrix\n",
    "    col1   = np.cos(n*data['t']).T\n",
    "    col2   = np.sin(n*data['t']).T\n",
    "    col3   = np.ones(len(data['t'])).T\n",
    "    \n",
    "    X      = np.vstack([col1, col2, col3]).T              # Basis matrix\n",
    "    Sigma  = np.diag(data['ey']**2)                       # Covariance matrix (data)\n",
    "    Weight = np.linalg.inv(Sigma)                         # Wheight matrix\n",
    "    Ca     = np.linalg.inv(X.T @ Weight @ X)              # Covariance matrix (parameters)\n",
    "    aMLE   = Ca @ X.T @ Weight @ data['y']                # Best fit parameters\n",
    "    aStd   = np.sqrt(np.diag(Ca))                         # Error on aMLE\n",
    "    Ra     = Ca/(aStd[:,np.newaxis]*aStd[np.newaxis,:])   # Correlation matrix (parameters)\n",
    "    \n",
    "    return X, Sigma, Weight, aMLE, aStd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "transsexual-nebraska",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-29T19:12:57.514500Z",
     "start_time": "2023-11-29T19:12:57.500514Z"
    }
   },
   "outputs": [],
   "source": [
    "Period = 6.5 # Period in days\n",
    "X, Sigma, Weight, aMLE, aStd = fit_model(data, Period)\n",
    "\n",
    "print(\"Best fit parameters : A = {:.3f} B = {:.3f} C = {:.3f}\".format(*aMLE))\n",
    "print(aStd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sonic-alfred",
   "metadata": {},
   "source": [
    "### Part 5 : Interval estimates and the Metropolis-Hastings algorithm\n",
    "#### 5.2 Implementation\n",
    ">#### Point a)\n",
    "Express the criterion of Eq. (7) as a function of the prior probabilities $p(\\theta)$, $p(\\theta')$ and the likelihoods $p(y|\\theta)$, $p(y|\\theta')$. What is the crucial advantage of the Metropolis-Hastings algorithm for the generation of samples from a posterior distribution, over a generation of samples with the inverse CDF?\n",
    "\n",
    "We can express the criterion\n",
    "\n",
    "\\begin{equation}\n",
    "\\alpha = \\mathrm{min}\\left( 1, \\frac{f(\\theta') q_{\\theta'}(\\theta_i)}{f(\\theta_i)q_{\\theta_i}(\\theta')} \\right)\n",
    "\\end{equation}\n",
    "\n",
    "Using the relation $p(\\theta|y) = \\frac{p(y|\\theta)p(\\theta)}{p(y)}$, and assuming that $q_{\\theta'}(\\theta_i)$ and $q_{\\theta_i}(\\theta')$ cancel because $q$ is symmetric (not in general, but it is the case in our project).\n",
    "\n",
    "\\begin{equation}\n",
    "\\alpha = \\mathrm{min} \\left( 1, \\frac{p(y|\\theta') p(\\theta')}{p(y|\\theta_i)p(\\theta_i)} \\right)\n",
    "\\end{equation}\n",
    "\n",
    "Advantage : No need to know $p(y)$, where, in general, no analytical expression can be found.\n",
    "\n",
    ">#### Point b)\n",
    "For numerical stability, the factor $\\alpha$ is not computed directly, but one computes its logarithm. Express the criterion of Eq. (7) as a function of the logarithms of the different distributions involved.\n",
    "\n",
    "\\begin{equation}\n",
    "\\alpha = \\mathrm{min} \\Big( \\;0 \\; , \\; \\log(p(y|\\theta')) + \\log(p(\\theta')) - \\log(p(y|\\theta_i)) - \\log(p(\\theta_i)) \\Big)\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "controversial-serial",
   "metadata": {},
   "source": [
    "##### Computing the logprior function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "handy-binding",
   "metadata": {},
   "source": [
    "For $A$, $B$, $C$ following a gaussian distribution :\n",
    "\n",
    "\\begin{equation}\n",
    "P(x, \\sigma) = \\frac{1}{\\sqrt{2\\pi}\\:\\sigma} \\exp \\left\\{ - \\frac{x^2}{2\\sigma^2}Â \\right\\}\n",
    "\\quad \\Longrightarrow \\quad\n",
    "\\log(P(x, \\sigma)) = -0.5 \\log\\left( 2\\pi\\sigma^2\\right) - \\frac{x^2}{2\\sigma^2}\n",
    "\\end{equation}\n",
    "\n",
    "$n$ following a uniform distribution over 0 and $4\\pi$ :\n",
    "\n",
    "\\begin{equation}\n",
    "P(n) = \\left\\{ \\begin{array}{cl} \\frac{1}{4\\pi} & \\mathrm{if} \\;\\; n \\in [0, 4\\pi] \\\\ 0 & \\mathrm{otherwise} \\end{array} \\right.\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "Its logarithm is given by $\\log(P(n)) = -\\log(4\\pi)$. \n",
    "\n",
    "We thus have :\n",
    "\\begin{equation}\n",
    "\\log(P(A)P(B)P(C)P(n)) = \\log(P(A)) + \\log(P(B)) + \\log(P(C)) + \\log(P(n)) = -\\frac{3}{2} \\log(2\\pi\\sigma^2) - \\frac{1}{2\\sigma^2} \\left(A^2 + B^2 + C^2 \\right) - \\log(4\\pi)\n",
    "\\end{equation}\n",
    "\n",
    "We can neglect the first constant because, in our case, it will be cancelled when computing the difference :\n",
    "\n",
    "\\begin{equation}\n",
    "\\log(P(\\theta)) = - \\frac{1}{2\\sigma^2} \\left(A^2 + B^2 + C^2 \\right) - \\log(4\\pi)\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baking-simon",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-29T19:13:46.092397Z",
     "start_time": "2023-11-29T19:13:46.086457Z"
    }
   },
   "outputs": [],
   "source": [
    "def logprior(theta, sigma=100):    \n",
    "    A = theta[0]\n",
    "    B = theta[1]\n",
    "    C = theta[2] \n",
    "    n = theta[3]\n",
    "    \n",
    "    if n >= 0 and n <= 4*np.pi:\n",
    "        return - (A**2 + B**2 + C**2) / (2 * sigma**2) - np.log(4*np.pi)\n",
    "    else:              # p(n) = 0 if n < 0 or n > 4 pi\n",
    "        return -np.inf # log(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "academic-express",
   "metadata": {},
   "source": [
    "##### Computing the log likelihood function\n",
    "\n",
    "The logarithm of the likelihood is given by :\n",
    "\n",
    "\\begin{equation}\n",
    "\\log(\\mathcal{L}) = \\sum_{k} \\left[ -\\frac{1}{2} \\log(2\\pi\\sigma_k^2) - \\frac{1}{2} \\frac{(y_k - V(t_k))^2}{\\sigma_k^2} \\right]\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loved-organ",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-29T19:13:47.086984Z",
     "start_time": "2023-11-29T19:13:47.081828Z"
    }
   },
   "outputs": [],
   "source": [
    "def V(t, theta):\n",
    "    A = theta[0]\n",
    "    B = theta[1]\n",
    "    C = theta[2]\n",
    "    n = theta[3]\n",
    "    \n",
    "    return A * np.cos(n*t) + B * np.sin(n*t) + C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "christian-coaching",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-29T19:13:48.328887Z",
     "start_time": "2023-11-29T19:13:48.321453Z"
    }
   },
   "outputs": [],
   "source": [
    "def loglikelihood(data, theta):\n",
    "    t  = data['t']\n",
    "    y  = data['y']\n",
    "    ey = data['ey']\n",
    "    return np.sum(-0.5 * np.log(2 * np.pi * ey**2) - 0.5 * ((y - V(t, theta))/ey)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "african-guitar",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-29T19:13:48.778206Z",
     "start_time": "2023-11-29T19:13:48.773355Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_proposal(theta, sigmas):\n",
    "    return np.random.normal(loc=theta, scale=sigmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ready-medium",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-29T19:13:49.315087Z",
     "start_time": "2023-11-29T19:13:49.304515Z"
    }
   },
   "outputs": [],
   "source": [
    "def mh_sampler(data, theta0, logprior, loglikelihood, proposal, nsamples):\n",
    "    \n",
    "    acc_rates = np.zeros(nsamples) # To store acceptance rate at each iteration\n",
    "    naccepted = 0                  # Number of accepted proposals\n",
    "    \n",
    "    thetas = np.ndarray(shape=(nsamples, 4))       # Chain\n",
    "    thetas[0] = theta0                             # First element of the chain\n",
    "\n",
    "    Tobs = np.max(data['t']) - np.min(data['t'])   # Observing time\n",
    "    \n",
    "    sa = 0.1\n",
    "    sb = 0.1\n",
    "    sc = 0.1\n",
    "    sn = 4./5. * (1./5.) * np.pi / Tobs\n",
    "    \n",
    "    sigmas = np.array([sa, sb, sc, sn])\n",
    "    \n",
    "\n",
    "    print(\"Running MCMC ...\")\n",
    "    print(\"     A,  B,  C,  n : {:.3f}, {:.3f}, {:.3f}, {:.3f},\".format(*theta0))\n",
    "    print(\"    sA, sB, sC, sn : {:.3f}, {:.3f}, {:.3f}, {:.3f}\".format(sa, sb, sc, sn))\n",
    "    \n",
    "    \n",
    "    for i in tqdm(range(1, nsamples)):    \n",
    "        newtheta  = proposal(thetas[i-1], sigmas)\n",
    "        DeltaProb =    loglikelihood(data, newtheta)    + logprior(newtheta)      \\\n",
    "                     - loglikelihood(data, thetas[i-1]) - logprior(thetas[i-1])\n",
    "        alpha     = np.min([0, DeltaProb])\n",
    "        u         = np.random.uniform(low=0, high=1)\n",
    "        \n",
    "        if u < np.exp(alpha):\n",
    "            thetas[i] = newtheta\n",
    "            naccepted += 1\n",
    "            \n",
    "        else:\n",
    "            thetas[i] = thetas[i-1]\n",
    "        \n",
    "        acc_rates[i] = naccepted/i\n",
    "        \n",
    "    return thetas, acc_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cooked-arthritis",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-29T19:15:17.397325Z",
     "start_time": "2023-11-29T19:13:51.090766Z"
    }
   },
   "outputs": [],
   "source": [
    "run = input(\"Run ? (y/n) -> \")\n",
    "\n",
    "if run in ['y', 'Y']:\n",
    "    n = 2 * np.pi/6.5\n",
    "    theta0 = list([*aMLE, n])\n",
    "    thetas, acc_rates = mh_sampler(data, theta0, logprior, loglikelihood, generate_proposal, nsamples=100000)\n",
    "    \n",
    "    \n",
    "chain_A = np.array([_[0] for _ in thetas])\n",
    "chain_B = np.array([_[1] for _ in thetas])\n",
    "chain_C = np.array([_[2] for _ in thetas])\n",
    "chain_n = np.array([_[3] for _ in thetas])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spare-greek",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-29T19:15:22.605941Z",
     "start_time": "2023-11-29T19:15:22.333194Z"
    }
   },
   "outputs": [],
   "source": [
    "x  = np.arange(0, len(acc_rates), 1)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 4))\n",
    "ax.set_xlabel(\"Sample\")\n",
    "ax.set_ylabel(\"Acceptance rate\")\n",
    "ax.plot(x, acc_rates)\n",
    "ax.axvline(len(acc_rates)//5, c='k')\n",
    "\n",
    "# Adding a rectangle on the plot\n",
    "R_xpos   = ax.get_xlim()[0]\n",
    "R_ypos   = ax.get_ylim()[0]\n",
    "R_width  = (len(acc_rates)//5)-ax.get_xlim()[0]\n",
    "R_height = ax.get_ylim()[1]+0.05\n",
    "\n",
    "R = plt.Rectangle((R_xpos, R_ypos), R_width, R_height, alpha=0.7, fc='grey')\n",
    "ax.add_patch(R)\n",
    "\n",
    "print(\"Mean acceptance rate : {:.1f}% (Without including grey part)\".format(100*np.mean(acc_rates[:len(acc_rates)//5])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unavailable-interference",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-29T19:15:27.062695Z",
     "start_time": "2023-11-29T19:15:25.344903Z"
    }
   },
   "outputs": [],
   "source": [
    "start = len(thetas)//5\n",
    "\n",
    "\n",
    "fig = corner.corner(thetas[start:], labels=['A', 'B', 'C', 'n'], dpi=300);\n",
    "\n",
    "# Mean and median values\n",
    "mean_A,   mean_B,   mean_C,   mean_n = np.mean(thetas, axis=0)\n",
    "median_A, median_B, median_C, median_n = np.median(thetas, axis=0)\n",
    "\n",
    "# Printing results\n",
    "print(\"{:>7} {:>10} {:>10}\".format(\"Param\", \"mean\", \"median\"))\n",
    "print(\"------------------------------\")\n",
    "[print(\"{:>7} {:>10.3f} {:>10.3f}\".format(idx, mea, med)) for idx, mea, med in zip(['A', 'B', 'C', 'n'], np.mean(thetas, axis=0), np.median(thetas, axis=0))]\n",
    "print(\"\\ntheta mle : {:.3f} {:.3f} {:.3f}\".format(*aMLE))\n",
    "\n",
    "\n",
    "fig.axes[0].axvline(mean_A,  c='r', label=\"mean\")\n",
    "fig.axes[5].axvline(mean_B,  c='r', label=\"mean\")\n",
    "fig.axes[10].axvline(mean_C, c='r', label=\"mean\")\n",
    "fig.axes[15].axvline(mean_n, c='r', label=\"mean\")\n",
    "\n",
    "fig.axes[0].axvline(median_A,  c='b', label=\"median\")\n",
    "fig.axes[5].axvline(median_B,  c='b', label=\"median\")\n",
    "fig.axes[10].axvline(median_C, c='b', label=\"median\")\n",
    "fig.axes[15].axvline(median_n, c='b', label=\"median\")\n",
    "\n",
    "fig.axes[0].legend(bbox_to_anchor=(1, 1));\n",
    "\n",
    "#fig.savefig(\"corner.png\", facecolor='w', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surrounded-profit",
   "metadata": {},
   "source": [
    "##### Point f)\n",
    "\n",
    "Let now estimate the minimal mass of the planet, given by $m\\sin(i)$. From the two expressions of $A$ and $B$, one can find an expression for $t_0$ :\n",
    "\n",
    "\\begin{equation}\n",
    "\\frac{A}{\\cos(nt_0)} = \\frac{B}{\\sin(nt_0)}\n",
    "\\quad \\Rightarrow \\quad\n",
    "nt_0 = \\arctan\\left( \\frac{B}{A} \\right)\n",
    "\\end{equation}\n",
    "\n",
    "Finally, we can use the expression for the coefficient $A$ in order to isolate $m\\sin(i)$ :\n",
    "\n",
    "\\begin{equation}\n",
    "m\\sin(i) = \\frac{AM^{2/3}}{(Gn)^{1/3}\\cos\\left(\\arctan\\left(\\frac{B}{A}\\right)\\right)} = \\frac{AM^{2/3}}{(Gn)^{1/3}} \\sqrt{\\left(1 + \\frac{B^2}{A^2}\\right)}\n",
    "\\end{equation}\n",
    "\n",
    "Where, in the last equality, we used the formula $\\cos(\\arctan(x)) = (x^2+1)^{-1/2}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "insured-concord",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-29T19:15:32.815222Z",
     "start_time": "2023-11-29T19:15:32.787888Z"
    }
   },
   "outputs": [],
   "source": [
    "G = const.G.value\n",
    "M_sun   = const.M_sun.value\n",
    "M_earth = const.M_earth.value\n",
    "M_Jup   = const.M_jup.value\n",
    "\n",
    "mass_min = (chain_A * M_sun**(2/3)) * np.sqrt(1 + (chain_B/chain_A)**2) / (G*(chain_n/(24*60*60)))**(1/3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quarterly-patch",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-29T19:15:33.918978Z",
     "start_time": "2023-11-29T19:15:33.372455Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "counts, bins, bars = ax.hist(mass_min/M_earth, bins=100);\n",
    "ax.axvline(np.mean(mass_min/M_earth), c='r', label='Mean')\n",
    "ax.axvline(np.median(mass_min/M_earth), c='orange', label='Median')\n",
    "ax.set_xlabel(\"Earth mass\");\n",
    "ax.set_ylabel(\"Counts\")\n",
    "ax.legend()\n",
    "print(\"Mean   : {:.3f}   (Earth mass)\".format(np.mean(mass_min/M_earth)))\n",
    "print(\"Median : {:.3f}   (Earth mass)\".format(np.median(mass_min/M_earth)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "excess-fleece",
   "metadata": {},
   "source": [
    "##### Point g)\n",
    "In order to find the smallest credible interval at level $\\alpha = 95\\%$, we start from the outside of the distribution (we defined the variable a as the index from the left, and b as the index from the right). We then iterate towards the middle of the distribution and stop when the probability outside is $>= 0.05$ ($= 1 - \\alpha$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "italic-marketing",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-29T19:15:37.232449Z",
     "start_time": "2023-11-29T19:15:36.880071Z"
    }
   },
   "outputs": [],
   "source": [
    "alpha = 0.95\n",
    "beta  = 1 - alpha\n",
    "total = np.sum(counts)\n",
    "\n",
    "a = 0            # index\n",
    "b = len(bins)-1  # index\n",
    "\n",
    "while a < b:\n",
    "    num = np.sum(counts[:a]) + np.sum(counts[b:])\n",
    "    \n",
    "    if num / total >= beta:\n",
    "        print(\"a = {} : {:.4f}, b = {} : {:.4f}\".format(a, bins[a], b, bins[b]))\n",
    "        break\n",
    "        \n",
    "    a += 1\n",
    "    b -= 1\n",
    "\n",
    "plt.hist(mass_min/M_earth, bins=100)\n",
    "plt.axvline(bins[a], c='r')\n",
    "plt.axvline(bins[b], c='r');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "played-prevention",
   "metadata": {},
   "source": [
    "For the second method (equal probability on each side), we compute the left and right probabilities separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "finished-shape",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-29T19:15:39.286454Z",
     "start_time": "2023-11-29T19:15:38.879640Z"
    }
   },
   "outputs": [],
   "source": [
    "total = np.sum(counts)\n",
    "alpha = 0.95\n",
    "beta  = 1 - alpha\n",
    "\n",
    "# Finding value on the left (a)\n",
    "a = 0\n",
    "for a in range(len(bins[:-1])):\n",
    "    num = np.sum(counts[:a])\n",
    "    if num/total >= beta/2:\n",
    "        print(\"a = {} : {:.4f}\".format(a, bins[a]))\n",
    "        break\n",
    "        \n",
    "# Finding value on the right (b)\n",
    "b = len(bins)-1\n",
    "for b in range(len(bins)-1, 0, -1):\n",
    "    num = np.sum(counts[b:])\n",
    "    if num / total >= beta/2:\n",
    "        print(\"b = {} : {:.4f}\".format(b, bins[b]))\n",
    "        break\n",
    "        \n",
    "plt.hist(mass_min/M_earth, bins=100)\n",
    "plt.axvline(bins[a], c='r')\n",
    "plt.axvline(bins[b], c='r');"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
