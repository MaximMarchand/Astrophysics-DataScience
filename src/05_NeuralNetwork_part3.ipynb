{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "yellow-polymer",
   "metadata": {},
   "source": [
    "Maxime Marchand\n",
    "# Astrophysics and Data Science : Project 5\n",
    "## Neural network from scrach : Part 3\n",
    "\n",
    "In this part, we train our neural network on the MNIST database, representing handwritten digits between 0 and 9. The dataset is made of 60'000 training digits, and 10'000 validation digits.\n",
    "\n",
    "In general, the images are first convolved and then reduced in order to decrease the number of input dimention, this code is just entering each pixels in the input layer, which is clearly not the most optimal implementation. But we still have ~87 % accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "marine-census",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-05T13:59:05.074803Z",
     "start_time": "2023-12-05T13:59:04.429300Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from _05_functions import *   # Functions presented in Part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hungry-singapore",
   "metadata": {},
   "source": [
    "The input files are really big, so after having applied the same steps presented in Part 1 on the data (linear normalization, separating pixels and classes, creating targets, etc...), the variables have been saved with the pickle package in order to make the code run faster. The commented cell below is what has been made to prepare the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hawaiian-slave",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File names --------------------------\n",
    "#trainFileName = 'Data/mnist_train.csv'\n",
    "#testFileName  = 'Data/mnist_test.csv'\n",
    "\n",
    "# Collecting data ---------------------------------------------------------\n",
    "#train_data    = np.loadtxt(trainFileName, delimiter=',', comments='label')\n",
    "#test_data     = np.loadtxt(testFileName, delimiter=',', comments='label')\n",
    "\n",
    "# Creating targets -----------------------------------------------\n",
    "#train_targets = np.zeros(shape=(len(training_set['vectors']),10))\n",
    "#test_targets  = np.zeros(shape=(len(testing_set['vectors']), 10))\n",
    "#\n",
    "#for i in range(len(train_targets)):\n",
    "#    train_targets[i, int(train_data[i, 0])] = np.ones(1)\n",
    "#\n",
    "#for i in range(len(test_targets)):\n",
    "#    test_targets[i, int(test_data[i, 0])] = np.ones(1)\n",
    "#\n",
    "#training_set = {\n",
    "#    'vectors'  : train_data[:, 1:],\n",
    "#    'classes'  : train_data[:, 0],\n",
    "#    'targets'  : train_targets\n",
    "#}\n",
    "#\n",
    "#testing_set = {\n",
    "#    'vectors'  : test_data[:, 1:],\n",
    "#    'classes'  : test_data[:, 0],\n",
    "#    'targets'  : test_targets    \n",
    "#}\n",
    "\n",
    "# Normalize the data -------------------------\n",
    "#for i in range(len(training_set['vectors'])):\n",
    "#    minim = np.min(training_set['vectors'][i])\n",
    "#    maxim = np.max(training_set['vectors'][i])\n",
    "#    training_set['vectors'][i] = (2 * (training_set['vectors'][i] - minim) / (maxim - minim)) - 1\n",
    "\n",
    "#Saving variables with pickle ------------------------\n",
    "#with open('./Data/mnist_train.pkl', 'wb') as outFile:\n",
    "#    pickle.dump(training_set, outFile)\n",
    "#with open('./Data/mnist_test.pkl', 'wb') as outFile:\n",
    "#    pickle.dump(testing_set, outFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "broken-scottish",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-22T12:39:37.202011Z",
     "start_time": "2023-07-22T12:39:36.749425Z"
    }
   },
   "outputs": [],
   "source": [
    "#Loading variables with pickle\n",
    "with open('./Data/mnist_train.pkl', 'rb') as inFile:\n",
    "    training_set = pickle.load(inFile)\n",
    "with open('./Data/mnist_test.pkl', 'rb') as inFile:\n",
    "    testing_set = pickle.load(inFile)\n",
    "    \n",
    "class_dim = len(np.unique(training_set['classes']))  # Number of possible outputs (3 in the case of wheat database)\n",
    "data_dim  = len(training_set['vectors'][0])          # Dimention of the data (7 in the case of wheat database)\n",
    "transfert_mode = 'sig'                               # Choose between 'sig', 'ReLU' and 'ReLU_dying'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "angry-still",
   "metadata": {},
   "source": [
    "Let have a look at some of the digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "central-handle",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-22T12:39:39.813548Z",
     "start_time": "2023-07-22T12:39:38.663270Z"
    }
   },
   "outputs": [],
   "source": [
    "numrows, numcols = 5, 10\n",
    "fig, ax = plt.subplots(nrows=numrows, ncols=numcols, figsize=(16, 8))\n",
    "\n",
    "idx=0 # Counter\n",
    "for i in range(numrows):\n",
    "    for j in range(numcols):\n",
    "        ax[i, j].xaxis.set_visible(False)\n",
    "        ax[i, j].yaxis.set_visible(False)\n",
    "        ax[i, j].imshow(training_set['vectors'][numrows*i+j].reshape((28, 28)), cmap='gray')\n",
    "        idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hairy-passenger",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-22T12:39:41.267430Z",
     "start_time": "2023-07-22T12:39:41.263175Z"
    }
   },
   "outputs": [],
   "source": [
    "#class_dim = len(np.unique(training_set['classes']))  # Number of possible outputs (3 in the case of wheat database)\n",
    "#data_dim  = len(training_set['vectors'][0])          # Dimention of the data (7 in the case of wheat database)\n",
    "\n",
    "# Architecture of the network\n",
    "#num_neurons_input  = data_dim\n",
    "#num_hidden_layers  = 1\n",
    "#num_neurons_hidden = 20\n",
    "#num_neurons_output = class_dim\n",
    "\n",
    "# Training parameters\n",
    "#num_epochs     = 1\n",
    "#learning_rate  = 0.05\n",
    "#transfert_mode = 'sig'   # Choose between 'sig', 'ReLU' and 'ReLU_dying'\n",
    "\n",
    "#network = generate_neural_network(num_neurons_input, num_hidden_layers, num_neurons_hidden, num_neurons_output)\n",
    "#network, vec_cost = train_network(network, num_epochs, learning_rate, training_set, transfert_mode)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "determined-reggae",
   "metadata": {},
   "source": [
    "The training of the network takes quite a long time, so I trained it, and saved the state of the network with the pickle module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "explicit-black",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-22T12:39:42.195445Z",
     "start_time": "2023-07-22T12:39:42.183646Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('./Data/network.pkl', 'rb') as inFile:\n",
    "    network = pickle.load(inFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "second-bailey",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-22T12:39:42.673948Z",
     "start_time": "2023-07-22T12:39:42.669551Z"
    }
   },
   "outputs": [],
   "source": [
    "def class_from_output(output):\n",
    "    \"\"\"\n",
    "    Converts target vector to class\n",
    "    \n",
    "    PARAMETERS\n",
    "        output : np.array\n",
    "        \n",
    "    RETURNS\n",
    "        0 if output == [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "        1 if output == [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "        2 if output == [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
    "        ...\n",
    "        9 if output == [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
    "    \"\"\"\n",
    "    return float(np.where(output == np.max(output))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chronic-lodge",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-22T12:39:45.853290Z",
     "start_time": "2023-07-22T12:39:44.524548Z"
    }
   },
   "outputs": [],
   "source": [
    "# We test the network with the validation data set\n",
    "predicted_values = np.ndarray(len(testing_set['vectors']))\n",
    "\n",
    "for i in range(len(testing_set['vectors'])):\n",
    "    entry      = testing_set['vectors'][i]                              # Data to put in network\n",
    "    network    = forward_propagation(network, entry, transfert_mode='sig') # Forward propagation \n",
    "    net_output = network[-1]['O']                                          # Predicted value from network\n",
    "    predicted_values[i] = class_from_output(net_output)                    # Storing the predicted class\n",
    "\n",
    "CM = np.zeros(shape=(class_dim, class_dim)) # Confusion Matrix\n",
    "\n",
    "for c in range(0, 10):     # c - class\n",
    "    for p in range(0, 10): # p - prediction\n",
    "        sel = (predicted_values == p) * (testing_set['classes'] == c)   # The * operator acts as the logic gate AND\n",
    "        CM[c, p] = len(sel[sel])\n",
    "\n",
    "print(\"Confusion matrix \\n\")\n",
    "print(\"{:<10} : {:>6} {:>6} {:>6} {:>6} {:>6} {:>6} {:>6} {:>6} {:>6} {:>6}\".format(\"Predicted\", *np.arange(10)))\n",
    "print(\"Classes\")\n",
    "for i in range(len(CM)):\n",
    "    [print(\"{:^12} {:>6} {:>6} {:>6} {:>6} {:>6} {:>6} {:>6} {:>6} {:>6} {:>6}\".format(i, *CM[i]))];\n",
    "    \n",
    "print(\"\\nAccuracy : {:.2f}%\".format(100*np.trace(CM)/np.sum(CM)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suited-productivity",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-22T12:39:51.162889Z",
     "start_time": "2023-07-22T12:39:50.993945Z"
    }
   },
   "outputs": [],
   "source": [
    "# Change idx to test some digits\n",
    "idx = 8\n",
    "entry      = testing_set['vectors'][idx]                         # Data to put in network\n",
    "network    = forward_propagation(network, entry, transfert_mode) # Forward propagation \n",
    "net_output = network[-1]['O']                                    # Predicted value from network\n",
    "predicted_values[i] = class_from_output(net_output)              # Storing the predicted class\n",
    "\n",
    "\n",
    "print(\"entry          :\", testing_set['classes'][idx])\n",
    "plt.imshow(entry.reshape(28, 28), cmap='gray')\n",
    "print(\"network output :\", predicted_values[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "copyrighted-seattle",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
